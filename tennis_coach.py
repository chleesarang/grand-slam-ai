import streamlit as st
import cv2  # ì˜ìƒì„ ìë¥´ëŠ” ë„êµ¬
import tempfile
import os
import base64
from openai import OpenAI

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì´êµìˆ˜ì˜ AI í…Œë‹ˆìŠ¤", page_icon="ğŸ¾", layout="wide")

# 2. ì œëª© ì„¤ì •
st.markdown("""
    <h1 style='text-align: left; margin-bottom: 0px;'>ğŸ¾ AI í…Œë‹ˆìŠ¤ ì½”ì¹˜</h1>
    <h5 style='text-align: left; color: gray; margin-top: -10px;'>by ì´êµìˆ˜</h5>
    <hr>
""", unsafe_allow_html=True)

# 3. API í‚¤ ì„¤ì •
if "OPENAI_API_KEY" in st.secrets:
    api_key = st.secrets["OPENAI_API_KEY"]
else:
    api_key = st.text_input("OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")

# --- ë‚´ë¶€ í•¨ìˆ˜: ì˜ìƒì„ ì´ë¯¸ì§€ í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ ---
def extract_frames(video_path, num_frames=5):
    """ì˜ìƒì—ì„œ ê· ë“±í•œ ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ base64ë¡œ ë³€í™˜"""
    video = cv2.VideoCapture(video_path)
    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    step = max(total_frames // num_frames, 1)
    
    base64_frames = []
    for i in range(0, total_frames, step):
        video.set(cv2.CAP_PROP_POS_FRAMES, i)
        success, frame = video.read()
        if not success:
            break
        # ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë©´ ë¹„ìš©ì´ ë§ì´ ë“œë¯€ë¡œ ë¦¬ì‚¬ì´ì§• (í­ 512px)
        height, width = frame.shape[:2]
        new_width = 512
        new_height = int(height * (new_width / width))
        frame = cv2.resize(frame, (new_width, new_height))
        
        _, buffer = cv2.imencode(".jpg", frame)
        base64_frames.append(base64.b64encode(buffer).decode("utf-8"))
        
        if len(base64_frames) >= num_frames:
            break
    video.release()
    return base64_frames

# 4. íƒ­ êµ¬ì„±
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ  í™ˆ", "ğŸ“– í•µì‹¬ ê¸°ìˆ  ê°€ì´ë“œ", "ğŸ–ï¸ ê·¸ë¦½ ì™„ì „ ì •ë³µ", "ğŸ¥ AI ìŠ¤ìœ™ ë¶„ì„"])

# (íƒ­ 1, 2, 3 ë‚´ìš©ì€ ë™ì¼í•˜ê²Œ ìœ ì§€ - ê³µê°„ ì ˆì•½ì„ ìœ„í•´ ìƒëµí–ˆì§€ë§Œ ê¸°ì¡´ ë‚´ìš© ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤)
with tab1:
    st.subheader("í™˜ì˜í•©ë‹ˆë‹¤! ì´êµìˆ˜ì˜ í…Œë‹ˆìŠ¤ ì—°êµ¬ì†Œì…ë‹ˆë‹¤.")
    st.write("ì´ì œ AIê°€ ë‹¹ì‹ ì˜ ì˜ìƒì„ **ì‹¤ì œë¡œ ë³´ê³ ** ë¶„ì„í•©ë‹ˆë‹¤.")

with tab2:
    st.header("í…Œë‹ˆìŠ¤ 3ëŒ€ í•µì‹¬ ê¸°ìˆ ")
    st.write("í¬í•¸ë“œ, ë°±í•¸ë“œ, ì„œë¸Œì˜ ê¸°ë³¸ ì›ë¦¬ë¥¼ ìµíˆì„¸ìš”.")

with tab3:
    st.header("ìƒí™©ë³„ ê·¸ë¦½ ê°€ì´ë“œ")
    st.write("ì»¨í‹°ë„¨íƒˆ, ì´ìŠ¤í„´, ì„¸ë¯¸ ì›¨ìŠ¤í„´ ê·¸ë¦½ì„ ìƒí™©ì— ë§ê²Œ ì¡ìœ¼ì„¸ìš”.")

# --- íƒ­ 4: ì§„ì§œ AI ìŠ¤ìœ™ ë¶„ì„ ---
with tab4:
    st.header("ğŸ¥ AI ìŠ¤ìœ™ ì •ë°€ ë¶„ì„ (Real Vision)")
    st.info("ğŸ’¡ ì˜ìƒì„ ì˜¬ë¦¬ë©´ AIê°€ ì£¼ìš” ì¥ë©´ 5ì»·ì„ ë³´ê³  ì •ë°€ ë¶„ì„í•©ë‹ˆë‹¤. (API ë¹„ìš© ë°œìƒ)")

    uploaded_file = st.file_uploader("ë¶„ì„í•  ì˜ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”", type=['mp4', 'mov', 'avi'])

    if uploaded_file is not None:
        st.video(uploaded_file)
        shot_type = st.radio("ì–´ë–¤ ìƒ·ì¸ê°€ìš”?", ["í¬í•¸ë“œ", "ë°±í•¸ë“œ", "ì„œë¸Œ", "ë°œë¦¬"], horizontal=True)
        
        if st.button("AI ë¶„ì„ ì‹œì‘ (Real Vision)"):
            if not api_key:
                st.error("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. Secretsì— ì„¤ì •í•˜ê±°ë‚˜ ìœ„ì— ì…ë ¥í•˜ì„¸ìš”.")
            else:
                client = OpenAI(api_key=api_key)
                
                with st.spinner(f"ì˜ìƒì„ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (ì•½ 15~30ì´ˆ ì†Œìš”)"):
                    try:
                        # 1. ì˜ìƒì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                        tfile.write(uploaded_file.read())
                        tfile.close()
                        
                        # 2. ì˜ìƒì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ (OpenCV ì‚¬ìš©)
                        frames = extract_frames(tfile.name, num_frames=5)
                        
                        # 3. ì„ì‹œ íŒŒì¼ ì‚­ì œ
                        os.unlink(tfile.name)

                        # 4. AIì—ê²Œ ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ ì „ì†¡
                        # ì´ë¯¸ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ì„œ ë³´ëƒ„
                        messages = [
                            {
                                "role": "system",
                                "content": "ë‹¹ì‹ ì€ ì„¸ê³„ì ì¸ í…Œë‹ˆìŠ¤ ì½”ì¹˜ 'ì´êµìˆ˜'ì…ë‹ˆë‹¤. ì œê³µëœ ì´ë¯¸ì§€ë“¤ì€ ì‚¬ìš©ìì˜ ìŠ¤ìœ™ ì˜ìƒì—ì„œ ì¶”ì¶œí•œ ì—°ì†ëœ ì¥ë©´ì…ë‹ˆë‹¤. ìì„¸, ë¼ì¼“ì˜ ìœ„ì¹˜, ì‹œì„  ë“±ì„ ì •ë°€í•˜ê²Œ ë¶„ì„í•˜ì—¬ êµì •í•  ì  3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
                            },
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": f"ì´ê²ƒì€ ë‚˜ì˜ {shot_type} ë™ì‘ì…ë‹ˆë‹¤. ìì„¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."},
                                ]
                            }
                        ]
                        
                        # ì¶”ì¶œëœ í”„ë ˆì„ë“¤ì„ ë©”ì‹œì§€ì— ì¶”ê°€
                        for frame in frames:
                            messages[0]["content"] += " (ì´ë¯¸ì§€ ì²¨ë¶€ë¨)" # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë³´ê°•
                            messages[1]["content"].append({
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{frame}"}
                            })

                        response = client.chat.completions.create(
                            model="gpt-4o",
                            messages=messages,
                            max_tokens=1000
                        )
                        
                        result = response.choices[0].message.content
                        st.success("ë¶„ì„ ì™„ë£Œ!")
                        st.markdown("### ğŸ“‹ ì´êµìˆ˜ì˜ ì •ë°€ ë¶„ì„ ë¦¬í¬íŠ¸")
                        st.markdown(result)
                        
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
